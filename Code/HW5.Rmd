---
title: "Homework_5"
author: "Nancy Zhang and Kyle Forrester"
date: "2025-10-13"
output: html_document
---

### Setup
First, we load in our data. This is the NOAA.new dataset from Canvas.
```{r setup, message=FALSE}
NOAA.new <- read.csv("/Users/nancyz/STAT486/Data/NewNOAA.csv") #replace with your path
x <- NOAA.new[,3] #temperature rise 
y <- NOAA.new[,2] #rate of billion-dollar disasters
```

#### Edited smoother.pck
This section contains the edited smoother.pck and its functions, with PRESS statistic in each smoother. The function chunks are fully commented, as this data was taken from Canvas/slides.
```{r edited-package, message=FALSE}
smoother.pck <- #received error that version of this package not available for this version of R
c("smoother.pck", "bin.mean", "gauss.mean", "gauss.reg", "gauss.mean.trunc", 
"gauss.reg.trunc", "my.hat.w")
bin.mean <-
function(x,y,nbin,xcol=2,do.plot=F)
{
  #order x and y
  o1<-order(x)
  x1<-x[o1]
  y1<-y[o1]
  #find min and max x
  r1<-range(x)
  #width of each bin = (max - min) / number of bins
  inc<-(r1[2]-r1[1])/nbin
  yvec<-NULL
  smat<-NULL
  #for each bin:
  for(i in 1:nbin){
        #find min and max values for the bin
        bin.low<-r1[1]+(i-1)*inc
        bin.high<-r1[1]+i*inc
        #I1: true if x1 is within the current bin or a later bin

        I1<-x1>=bin.low
        #I2: true if x1 is within the current bin or an earlier bin

if(i<nbin){
        I2<-x1<bin.high
}else{
        I2<-x1<=(bin.high+200)
}       #I3: true if both I1 and I2 are true, meaning x1 
        #is within the current bin
        I3<-as.logical(I1*I2)
        #find mean of the bucket
        yval<-mean(y1[I3])
        n1<-sum(I3)
        matdum<-NULL
        for(i in 1:n1){
        matdum<-rbind(matdum,I3*1/n1)
        }
        #convert values in each bucket to the mean and add to matrix
        smat<-rbind(smat,matdum)
        yvec<-c(yvec,rep(yval,n1))
  }
n99<-length(x1)
#calculate degrees of freedom, delta1, delta2, and R based on number of data points
dferror<-length(x1)-sum(diag(2*smat-smat%*%(t(smat))))
delta1<-sum(diag(t(diag(n99)-smat)%*%(diag(n99)-smat)))
R<-t(diag(n99)-smat)%*%(diag(n99)-smat)
delta2<-2*sum(diag(R%*%R))
#plot if enabled
if(isTRUE(do.plot)) lines(x1,as.numeric(smat%*%y1),col=xcol)
#calculate residuals and use PRESS function on the sum of squares
ypred<-y1
ypred<-smat%*%y1
resid<-y1-ypred
PRESS<-sum((resid/(1-diag(smat)))^2) 
#return
list(smat=smat,df=sum(diag(smat)),dferror=dferror,delta1=delta1,delta2=delta2,resid=resid,pred=ypred,x=x,press=PRESS)
                
}

gauss.mean <-
function(x,y,lambda,xcol=3,do.plot=T)
{
#order data
o1<-order(x)
x1<-x[o1]
y1<-y[o1]
r1<-range(x)
smat<-NULL
#for each data point
n1<-length(x1)
for(i in 1:n1){
        #take a sample with the data point as the mean and lambda as the standard deviation
        v1<-dnorm(x1,x1[i],lambda)
        #normalize vector by dividing by mean and add to matrix
        v1<-v1/sum(v1)
        smat<-rbind(smat,v1)
}
yhat<-smat%*%y1
#plot if enabled
if(do.plot){
lines(x1,yhat,col=xcol)
}
n99<-length(x1)
#calculate degrees of freedom, delta1, delta2, and R based on number of data points
dferror<-length(x1)-sum(diag(2*smat-smat%*%(t(smat))))
delta1<-sum(diag(t(diag(n99)-smat)%*%(diag(n99)-smat)))
R<-t(diag(n99)-smat)%*%(diag(n99)-smat)
delta2<-2*sum(diag(R%*%R))
#calculate residuals and use PRESS function on the sum of squares
resid<-y1-smat%*%y1
ypred<-y1
ypred[o1]<-smat%*%y1
PRESS<-sum((resid/(1-diag(smat)))^2)
#return
list(smat=smat,df=sum(diag(smat)),dferror=dferror,delta1=delta1,delta2=delta2,resid=resid,pred=ypred,press=PRESS)
        
}

gauss.reg <-
function(x,y,lambda,xcol=4,do.plot=T)
{
#order data
o1<-order(x)
x1<-x[o1]
y1<-y[o1]
r1<-range(x)
smat<-NULL
n1<-length(x1)
#for each data point
for(i in 1:n1){
        #take a sample with the data point as the mean and lambda as the standard deviation
        v1<-dnorm(x1,x1[i],lambda)
        #normalize vector by dividing by mean
        v1<-v1/sum(v1)
        #generate hat matrix
        H1<-my.hat.w(x1,v1)
        smat<-rbind(smat,H1[i,])
}
yhat<-smat%*%y1
#plot of enabled
if(do.plot){
lines(x1,yhat,col=xcol)
}
n99<-length(x1)
#calculate degrees of freedom, delta1, delta2, and R based on number of data points
dferror<-length(x1)-sum(diag(2*smat-smat%*%(t(smat))))
delta1<-sum(diag(t(diag(n99)-smat)%*%(diag(n99)-smat)))
R<-t(diag(n99)-smat)%*%(diag(n99)-smat)
delta2<-2*sum(diag(R%*%R))
#calculate residuals
resid<-y1-smat%*%y1
ypred<-y1
ypred[o1]<-smat%*%y1
PRESS<-sum((resid/(1-diag(smat)))^2)  #added PRESS statistic calculation
#return
list(smat=smat,df=sum(diag(smat)),dferror=dferror,delta1=delta1,delta2=delta2,resid=resid,pred=ypred,press=PRESS)
}

gauss.mean.trunc <-
function(x,y,lambda,nnn,xcol=5,do.plot=T)
{
#order data 
o1<-order(x)
x1<-x[o1]
y1<-y[o1]
r1<-range(x)
smat<-NULL
n1<-length(x1)
trunc.val<-n1-nnn
#for each data point
for(i in 1:n1){
  #generate sample with sd lambda and mean x1[i]
        v1<-dnorm(x1,x1[i],lambda)
        #order vector
        o2<-order(v1)              
        #remove values less than the threshold for truncating
        thresh<-v1[o2[trunc.val]]
        v1<-v1*(v1>thresh)
        #normalize and add to matrix
        v1<-v1/sum(v1)
        smat<-rbind(smat,v1)
}
yhat<-smat%*%y1
#graph if enabled
if(do.plot){
lines(x1,yhat,col=xcol)
}
n99<-length(x1)
#calculate degrees of freedom, delta1, delta2, and R based on number of data points
dferror<-length(x1)-sum(diag(2*smat-smat%*%(t(smat))))
delta1<-sum(diag(t(diag(n99)-smat)%*%(diag(n99)-smat)))
R<-t(diag(n99)-smat)%*%(diag(n99)-smat)
delta2<-2*sum(diag(R%*%R))
#predict y values and calculate residuals
resid<-y1-smat%*%y1
ypred<-y1
ypred[o1]<-smat%*%y1
PRESS<-sum((resid/(1-diag(smat)))^2)  #added PRESS statistic calculation
#return
list(smat=smat,df=sum(diag(smat)),dferror=dferror,delta1=delta1,delta2=delta2,resid=resid,pred=ypred,press=PRESS)
                
}

gauss.reg.trunc <-
function(x,y,lambda,nnn,xcol=6,do.plot=T)
{
#order data
o1<-order(x)
x1<-x[o1]
y1<-y[o1]
r1<-range(x)
smat<-NULL
n1<-length(x1)
trunc.val<-n1-nnn
#for all data
for(i in 1:n1){
        #generate sample with sd lambda and mean x1[i]
        v1<-dnorm(x1,x1[i],lambda)
        #order vector
        o2<-order(v1)       
        #remove values less than threshold for truncating
        thresh<-v1[o2[trunc.val]]
        v1<-v1*(v1>thresh)
        #normalize vector
        v1<-v1/sum(v1)
        #generate hat matrix
        H1<-my.hat.w(x1,v1)
        smat<-rbind(smat,H1[i,])
}
yhat<-smat%*%y1
if(do.plot){ #plot if enabled
lines(x1,yhat,col=xcol)
}
n99<-length(x1)
#calculate degrees of freedom, delta1, delta2, and R based on number of data points
dferror<-length(x1)-sum(diag(2*smat-smat%*%(t(smat))))
delta1<-sum(diag(t(diag(n99)-smat)%*%(diag(n99)-smat)))
R<-t(diag(n99)-smat)%*%(diag(n99)-smat)
delta2<-2*sum(diag(R%*%R))
#predict y values and calculate residuals
resid<-y1-smat%*%y1
ypred<-y1
ypred[o1]<-smat%*%y1
PRESS<-sum((resid/(1-diag(smat)))^2)  #added PRESS statistic calculation
#return
list(smat=smat,df=sum(diag(smat)),dferror=dferror,delta1=delta1,delta2=delta2,resid=resid,pred=ypred,press=PRESS)
}

my.hat.w <-
function(x,wt){
x1<-cbind(1,x)
x1%*%solve(t(x1)%*%diag(wt)%*%x1)%*%t(x1)%*%(diag(wt))
}
```

#### Comparing Smoothers with PRESS and Plots
This section is to apply each smoother to the NOAA.new data using the parameters given in slide 17. The reference from the slides is provided first, then the updated code with more readability is below. 
```{r param-reference}
#plot(NOAA1[,3],NOAA1[,2],xlab="temperature rise",ylab="rate of billion dollar
#weather disasters")
#dum<-bin.mean(NOAA1[,3],NOAA1[,2],6)
#dum<-gauss.mean(NOAA1[,3],NOAA1[,2],.063)
#gauss.reg(NOAA1[,3],NOAA1[,2],.078,do.plot=T)
#gauss.mean.trunc(NOAA1[,3],NOAA1[,2],.063,20,do.plot=T)
#gauss.reg.trunc(NOAA1[,3],NOAA1[,2],.08,17,do.plot=T)
#lines(lowess(NOAA1[,3],NOAA1[,2]),col=7)
#lines(smooth.spline(NOAA1[,3],NOAA1[,2]),col=8)
```

```{r plot-esimates}
#base plot where we'll have all our smoothers on 
plot(x, y, xlab = "temperature rise", ylab = "rate of billion-dollar disasters", pch = 19, cex = 0.7)

#refit with plotting turned on for ALL
fit_bin<-bin.mean(x, y, nbin = 6, xcol = 2, do.plot = TRUE)  #bin.mean function 
fit_gm<-gauss.mean(x, y, lambda = 0.063, xcol = 3, do.plot = TRUE) #gauss.mean function
fit_gr<-gauss.reg(x,  y, lambda = 0.078, xcol = 4, do.plot = TRUE) #gauss.reg function
fit_gm_trunc<-gauss.mean.trunc(x, y, lambda = 0.063, nnn = 20, xcol = 5, do.plot = TRUE) #gauss mean truncated function
fit_gr_trunc<-gauss.reg.trunc(x,  y, lambda = 0.08, nnn = 17, xcol = 6, do.plot = TRUE)
#gauss reg truncated function

#legend for the lines
legend("topleft", inset = 0.02, bty = "n", lwd = 2, lty = rep(1, 5), col = c(2,3,4,5,6), 
       legend = c("bin.mean (nbin=6)",
                  "gauss.mean (λ=0.063)",
                  "gauss.reg (λ=0.078)",
                  "gauss.mean.trunc (λ=0.063, nnn=20)",
                  "gauss.reg.trunc  (λ=0.08, nnn=17)"))

#comparing PRESS in a table:
press_table <- data.frame(
  smoother = c("bin.mean (nbin=6)",
               "gauss.mean (λ=0.063)",
               "gauss.reg (λ=0.078)",
               "gauss.mean.trunc (λ=0.063, nnn=20)",
               "gauss.reg.trunc (λ=0.08,  nnn=17)"),
  PRESS = c(fit_bin$press,
            fit_gm$press,
            fit_gr$press,
            fit_gm_trunc$press,
            fit_gr_trunc$press))
print(press_table)
```

#### Greedy Random Search Function 
This function references the pseudocode from slide 19 of Class 9. It's purpose is to find better values of the adjustable parameters, based on minimizing PRESS. 
```{r greedy}
greedy.search <- function(fit.eval,init.gen,perturb.gen,in.bounds,max.no.improve=300,target=Inf){
#do a random fit, choose parameters = pi0
pi0 <- init.gen()
crit0 <- fit.eval(pi0)#check and save fit

best.par <- pi0
best.crit <- crit0
noimp <- 0
#while fit not as good as criterion-> we use patience OR target
while(noimp < max.no.improve && best.crit > target)
  {#randomly perturb parameters, pi0 + small increments
    cand <- perturb.gen(best.par)
     #check if parameters meet any constraints
     if(in.bounds(cand)){
       #check fit
        ccrit <- fit.eval(cand)
        #if better save new parameters as pi0
        if(ccrit + 1e-12 < best.crit)
          {best.par <- cand
           best.crit <- ccrit
           noimp <- 0
          }
        else
          {noimp <- noimp + 1
          }
        }
     else{noimp <- noimp + 1
         }
 }
#output pi0 and final fit criterion
list(par=best.par,press=best.crit,tries=noimp)}
```

